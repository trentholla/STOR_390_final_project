---
title: 'EDA: Initial Results'
author: 'STOR 390: Group 5'
output: html_document
---

# --------------------------------------------------------------------

```{r setup, include=F}
library(tidyverse)
library(scales)
library(car)
```

###The Data

The two data sets, one from a Math class and the other from a Portuguese Class, are imported and merged. Observations with a 0 as the final grade (G3) were dropped, as the other variables did not support this outcome. We assume there were other factors that led to the 0 final scores (e.g. the student did not take the assessment). We also removed the observation with the sole final grade of 1 as an outlier (see grouped summary table below). 

```{r data}
# Read in data
math <- read.table("student-mat.csv", sep=";", header=TRUE)
port <- read.table("student-por.csv", sep=";", header=TRUE)


# Merge data to look at general student aptitude rather than separate math/Portuguese scores 
math <- mutate(math, class = "M")
port <- mutate(port, class = "P")

data <- rbind(math, port)


# Check final score distributions
group_by(data, G3) %>%
    summarize(cnt = n())

# Remove observations with 0 or 1 as G3 score
data <- data[data$G3 != 0,]
data <- data[data$G3 != 1,]
```

```{r factorization, include=F}
data <- mutate(data, Dalc = factor(Dalc),
               Walc = factor(Walc),
               health = factor(health),
               studytime = factor(studytime))
```

# --------------------------------------------------------------------

### Factors Affecting Final Grades

#### Studying

Is our intutition that students who study more perform better correct? Weekly study time is divided into 4 groups: where "1"" is less than 2 hours and "4"" is greater than 10. We see in the plot below that on average, final grades increase as study time increases.
```{r study, echo=F}
ggplot(data, aes(x = studytime, y = G3))+ 
    geom_boxplot() + 
    labs(x = 'Weekly Study Time', y = 'Final Grade', title = 'Studying Improves Final Grades') +
    theme_classic()
```

#### Absences

As expected, the more time a student is absent during the year, the lower their final grade is. However, we do not know if the lower grade is specifically because they missed class and the infomation taught that day. It's possbile that the reason they are absent (e.g. health issues) is actually the causing the lower grade.  
```{r absences, echo=F}
ggplot(data, aes(x = absences, y = G3)) + 
    geom_jitter(width = 1) + 
    geom_smooth(method = "lm", color = "red") +
    labs(x = "Number of Absences", y = "Final Grade", title = "Absences lead to lower final grades")

```

#### Parent's Education

A student's final grade increases the higher of level of education that their parents have. The plot for the mother's education is below. We also found that family educational support increases with the parents' education. This is logical, as parents with higher levels of education backgrounds would be more prepared to help their student with homework or other educaiton needs. 
```{r medu, echo=F}
ggplot(data, aes(x = Medu, y = G3)) + 
    geom_jitter(width = 1) + 
    geom_smooth(method = "lm", color = "red") + 
    labs(x = "Mother Education Level", y = "Final Grade", title = "Student's perform better the higher the level of education of their mothers")

```


#### Health

The following graph has an interesting result, as the healthiest group of students (5) have one of the lowest average grades (which is somewhat counterintuitive). However, the difference in average grades in by less than 1 point among all health levels. 
```{r health, echo=F}
ggplot(data, aes(x = health, y = G3)) +  
    geom_boxplot() + 
    labs(x = 'Health Status', y = 'Final Grade', title = 'Final Grade Not Impacted by Health') +
    theme_classic()
```

# --------------------------------------------------------------------

### Other Interesting Relationships

#### Why Students Choose a School

We can see below that a higher percentage of the students at Gabriel Pereira chose that school for it's reputation. It makes sense that Gabriel Pereira would have a better reputation, since it has higher scores in both Math and Portuguese. 
```{r reason, echo=F}
ggplot(data, aes(x = school, fill = reason)) + 
    geom_bar(position = "fill") + 
    scale_y_continuous(labels = percent) + 
    scale_x_discrete(labels = c("Gabriel Pereira" , "Mousinho da Silveira")) +
    labs(x = "School", y = "Percent of Student Population", title = "Higher percentage of students chose Gabriel Pereira for it's reputation") +
    theme_classic()

ggplot(data, aes(x = school, y = G3, color = class)) + 
    geom_boxplot() +
    scale_x_discrete(labels = c("Gabriel Pereira" , "Mousinho da Silveira")) +
    scale_color_discrete(name = "Type of Class", labels = c("Math", "Portuguese")) +
    labs(x = "School", y = "Final Grade", title = "Gabriel Pereira students have higher average scores in both math and Portuguese") + 
    theme_classic()


```

#### Genders and Drinking Habits

Male students drink more than females, but both genders increase their consumption over the weekend.
```{r drinking, echo=F}
ggplot(data, aes(x = sex, fill = Dalc)) + 
    geom_bar(position = "fill") + 
    scale_y_continuous(labels = percent) +
    scale_x_discrete(labels = c("Female" , "Male")) +
    labs(x = "Sex", y = "Percent of Population", title = "Male students drink more than females on workdays") +
    theme_classic()

ggplot(data, aes(x = sex, fill = Walc)) + 
    geom_bar(position = "fill") + 
    scale_y_continuous(labels = percent) +
    scale_x_discrete(labels = c("Female" , "Male")) +
    labs(x = "Sex", y = "Percent of Population", title = "All students increase alcohol consumption on the weekend") +
    theme_classic()
```


# --------------------------------------------------------------------

### Preliminary Models

As for the initial model, a simple linear regression has a high R^2 value and is a good starting place for modelling. This was accomplished by splitting the data into a training and test set. The models were created using the training set and tested on the test set in order to prevent overfitting. The predicted values given by the models come close to the actual ones, while the test errors are only slightly greater than the training errors. The variables that seemed to impact the final grade the most were the previous test grades. While this makes sense, it does not help determine if certain student behaviors impact their grade. For further testing, more models will be made that do not rely as heavily on past test scores as these.

```{r linear}
#training and test sets ------------------------------------------

n <- dim(data)[1]

# number of observations that go in the training st
n_tr <- floor(n * .8)


# randomly select n_tr numbers, without replacement, from 1...n
tr_indices <- sample(x=1:n, size=n_tr, replace=FALSE)

# break the data into a non-overlapping train and test set
train <- data[tr_indices, ]
test <- data[-tr_indices, ]


#comprehensive linear model ----------------------------------- 
model1 <- lm(G3 ~ school + sex + age + address + famsize + Pstatus + Medu + Fedu + Mjob + Fjob+ reason + guardian + traveltime + studytime + failures + schoolsup + famsup + paid + activities + nursery + higher + internet + romantic + famrel + freetime + goout + Dalc + Walc + health + absences + G1 + G2 + class, train)

MSE1 <- mean(model1$residuals^2)

#other models -------------------------------------------
model2 <- lm(G3 ~ age + schoolsup + paid + absences + G1 + G2 + class, train)
MSE2 <- mean(model2$residuals^2)

model3 <- lm(G3 ~ G1 + G2 + class, train, na.action = na.omit)
MSE3 <- mean(model3$residuals^2)

model4 <- lm(G3 ~ age + schoolsup + paid + absences + G1 + G2 +I(G1^2) + I(G2^2) + class, train)
MSE4 <- mean(model4$residuals^2)

model5 <- lm(G3 ~ absences + G1 + G2 + I(G1*G2) + class, train)
MSE5 <- mean(model5$residuals^2)

models <- list(model1, model2, model3, model4, model5)

#error --------------------------------------------------
error <- tibble(model_number=c(1,2,3,4,5),
                MSE_tr=c(MSE1, MSE2, MSE3, MSE4, MSE5))

error <- error %>% 
    add_column(MSE_tst=rep(0, 5))

for(i in 1:5){
    
    # grab the trained model
    model <- models[[i]]
    
    # get the predictions for the test data, compute the residuals
    
    test_results <- test %>% 
        mutate(G3_pred = predict(model, newdata=test)) %>% 
        mutate(resid_sq = (G3-G3_pred)^2) 
    
    # compute the MSE
    mst_tst <- summarise(test_results, mse_tst = mean(resid_sq))[[1]]
    
    error[i, 'MSE_tst'] <- mst_tst
}

error %>% 
    rename(tr=MSE_tr, tst=MSE_tst) %>% 
    gather(key=type, value=error, tr, tst) %>% 
    ggplot() +
    geom_point(aes(x=type, y=log10(error), color=type)) +
    geom_line(aes(x=type, y=log10(error), color=type)) + 
    labs(x = 'Model Number', y = 'log10(Error)', title = 'Comparison of Training and Test Errors')
```

