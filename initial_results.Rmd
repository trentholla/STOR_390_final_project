---
title: 'EDA: Initial Results'
author: 'STOR 390: Group 5'
output: html_document
---
# ----------------------------------------------------
The two data sets, one from a Math class and the other from a Portugese Class, are imported and merged. Observations with a 0 as the final grade were dropped, as the other variables did not support this outcome, meaning there were other factors beyond this data that influenced the scores.
```{r}
library(tidyverse)
library(scales)

# Read in data
math <- read.table("student-mat.csv", sep=";", header=TRUE)
port <- read.table("student-por.csv", sep=";", header=TRUE)

# merge data to look at general aptitude 
math <- mutate(math, class = "M")
port <- mutate(port, class = "P")

data <- rbind(math, port)


# remove those with 0 or 1 as G3 score
group_by(data, G3) %>%
    summarize(cnt = n())

data <- data[data$G3 != 0,]
data <- data[data$G3 != 1,]
```

# --------------------------------------------------------------------
Does studying improve grades? For the most part, yes. There is a general increasing trend between the 4 study time groups. This variable was also considered significant by the linear model, meaning the trend is statistically significant as well.
```{r}
ggplot(data, aes(x = studytime, y = G3, color = class, shape = class))+ geom_jitter() + 
    geom_smooth(method = "lm") + 
    labs(x = 'Weekly Study Time', y = 'Final Grade', title = 'Studying Improves Final Grades')
```

This graph has the most interesting result, for the healthiest individuals (5) have a lower average grade than every other health level. This could be for many reasons, such as a greater sample size or these students focus on their health more than school. This theory can be tested with another plot of health vs free time, but that graph is inconclusive just by looking at it.
```{r}
ggplot(data, aes(x = health, y = G3, color = class, shape = class)) +  geom_jitter() + geom_smooth(method = "lm") +
    labs(x = 'Health Status', y = 'Final Grade', title = 'Final Grade Not Impacted by Health')

ggplot(data, aes(x = health, y = freetime, color = class, shape = class)) +  geom_jitter() + geom_vline(xintercept = 0.5:5.5) + geom_hline(yintercept = 0.5:5.5) +
    labs(x = 'Health Status', y = 'Free Time', title = 'Final Grade Not Impacted by Health')
```

As for the initial model, a simple linear regression has a high R^2 value and is a good starting place for modelling. This was accomplished by splitting the data into a training and test set. The models were created using the training set and tested on the test set in order to prevent overfitting. The predicted values given by the models come close to the actual ones, while the test errors are only slightly greater than the training errors. Another interesting find is that most of the variables were not statistically significant in the regression.
```{r}
#training and test sets ------------------------------------------
n <- dim(data)[1]

# number of observations that go in the training st
n_tr <- floor(n * .8)


# randomly select n_tr numbers, without replacement, from 1...n
tr_indices <- sample(x=1:n, size=n_tr, replace=FALSE)

# break the data into a non-overlapping train and test set
train <- data[tr_indices, ]
test <- data[-tr_indices, ]


#comprehensive linear model ----------------------------------- 
woah <- lm(G3 ~ school + sex + age + address + famsize + Pstatus + Medu + Fedu + Mjob + Fjob+ reason + guardian + traveltime + studytime + failures + schoolsup + famsup + paid + activities + nursery + higher + internet + romantic + famrel + freetime + goout + Dalc + Walc + health + absences + G1 + G2 + class, train)

summary(woah)
vif(woah)

#other models -------------------------------------------
model2 <- lm(G3 ~ age + schoolsup + paid + absences + G1 + G2 + class, train)
summary(model2)
MSE2 <- mean(model2$residuals^2)

model3 <- lm(G3 ~ G1 + G2 + class, train, na.action = na.omit)
summary(model3)
MSE3 <- mean(model3$residuals^2)

model4 <- lm(G3 ~ age + schoolsup + paid + absences + G1 + G2 +I(G1^2) + I(G2^2) + class, train)
summary(model4)
MSE4 <- mean(model4$residuals^2)

model5 <- lm(G3 ~ absences + G1 + G2 + I(G1*G2) + class, train)
summary(model5)
MSE5 <- mean(model5$residuals^2)

models <- list(model1, model2, model3, model4, model5)

#error --------------------------------------------------
error <- tibble(model_numberr=c(1,2,3,4,5),
                MSE_tr=c(MSE1, MSE2, MSE3, MSE4, MSE5))

ggplot(error)+
    geom_point(aes(x=model_number, y=MSE_tr)) +
    geom_line(aes(x=model_number, y=MSE_tr)) +
    labs(x = 'Model Number', y = 'Training Error', title = 'Training Error for the Models')

error <- error %>% 
    add_column(MSE_tst=rep(0, 5))

for(i in 1:5){
    
    # grab the trained model
    model <- models[[i]]
    
    # get the predictions for the test data, compute the residuals
    
    test_results <- test %>% 
        mutate(G3_pred = predict(model, newdata=test)) %>% 
        mutate(resid_sq = (G3-G3_pred)^2) 
    
    # compute the MSE
    mst_tst <- summarise(test_results, mse_tst = mean(resid_sq))[[1]]
    
    error[i, 'MSE_tst'] <- mst_tst
}

error %>% 
    rename(tr=MSE_tr, tst=MSE_tst) %>% 
    gather(key=type, value=error, tr, tst) %>% 
    ggplot() +
    geom_point(aes(x=degree, y=log10(error), color=type)) +
    geom_line(aes(x=degree, y=log10(error), color=type)) + 
    labs(x = 'Model Number', y = 'log10(Error)', title = 'Comparison of Training and Test Errors')
error
```

